"""
title: AWS Bedrock Nova Function (Pipe)
author: Vince Castillo
date: 2024-12-13
version: 1.0
license: MIT
description: A pipe for generating text and processing images with Amazon's Nova models via AWS Bedrock API
environment_variables: AWS_ACCESS_KEY, AWS_SECRET_KEY, AWS_REGION_NAME
"""

import base64
import json
import logging
from io import BytesIO
from typing import List, Union, Generator, Iterator
import os
import time

import boto3
import requests
from pydantic import BaseModel, Field
from botocore.exceptions import ClientError

from open_webui.utils.misc import pop_system_message

logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)


class Pipe:
    class Valves(BaseModel):
        AWS_ACCESS_KEY: str = Field(default="")
        AWS_SECRET_KEY: str = Field(default="")
        AWS_REGION_NAME: str = Field(default="")

    def __init__(self):
        print("Method called: __init__")
        self.type = "manifold"
        self.id = "aws_bedrock_nova_pipe"
        self.name = "Nova via Bedrock: "
        self.valves = self.Valves(
            **{
                "AWS_ACCESS_KEY": os.getenv("AWS_ACCESS_KEY", ""),
                "AWS_SECRET_KEY": os.getenv("AWS_SECRET_KEY", ""),
                "AWS_REGION_NAME": os.getenv("AWS_REGION_NAME", ""),
            }
        )
        print(f"Valves initialized:{self.valves}")

    def get_bedrock_client(self):
        """Creates and returns a Bedrock client if credentials are available."""
        print("Method called: get_bedrock_client")
        if (
            self.valves.AWS_ACCESS_KEY
            and self.valves.AWS_SECRET_KEY
            and self.valves.AWS_REGION_NAME
        ):
            try:
                bedrock = boto3.client(
                    aws_access_key_id=self.valves.AWS_ACCESS_KEY,
                    aws_secret_access_key=self.valves.AWS_SECRET_KEY,
                    service_name="bedrock",
                    region_name=self.valves.AWS_REGION_NAME,
                )
                print("Bedrock client created successfully")
                return bedrock
            except Exception as e:
                print(f"Error creating bedrock client: {e}")
                return None
        print("No credentials available for Bedrock client")
        return None

    def get_bedrock_runtime_client(self):
        """Creates and returns a Bedrock runtime client if credentials are available."""
        print("Method called: get_bedrock_runtime_client")
        if (
            self.valves.AWS_ACCESS_KEY
            and self.valves.AWS_SECRET_KEY
            and self.valves.AWS_REGION_NAME
        ):
            try:
                bedrock_runtime = boto3.client(
                    aws_access_key_id=self.valves.AWS_ACCESS_KEY,
                    aws_secret_access_key=self.valves.AWS_SECRET_KEY,
                    service_name="bedrock-runtime",
                    region_name=self.valves.AWS_REGION_NAME,
                )
                print("Bedrock runtime client created successfully")
                return bedrock_runtime
            except Exception as e:
                print(f"Error creating bedrock runtime client: {e}")
                return None
        print("No credentials available for Bedrock runtime client")
        return None

    def on_startup(self):
        """Called when the server starts."""
        print("Method called: on_startup")
        logger.info(f"on_startup:{__name__}")

    def on_shutdown(self):
        """Called when the server stops."""
        print("Method called: on_shutdown")
        logger.info(f"on_shutdown:{__name__}")

    def on_valves_updated(self):
        """Called when the valves (credentials) are updated."""
        print("Method called: on_valves_updated")
        logger.info(f"on_valves_updated:{__name__}")

    def get_models(self):
        """Fetches available Amazon Nova models from AWS Bedrock."""
        print("Method called: get_models")
        bedrock = self.get_bedrock_client()
        if bedrock:
            try:
                print("Fetching models from Bedrock")
                response = bedrock.list_foundation_models(
                    byProvider="Amazon", byInferenceType="ON_DEMAND"
                )
                models = [
                    {
                        "id": model["modelId"],
                        "name": model["modelName"],
                    }
                    for model in response["modelSummaries"]
                    if "nova" in model["modelId"].lower()
                ]
                print(f"Found {len(models)} models")
                return models
            except Exception as e:
                print(f"Error fetching models: {e}")
                return [
                    {
                        "id": "error",
                        "name": "Could not fetch models from Bedrock, please update the Access/Secret Key in the valves.",
                    },
                ]
        else:
            print("No Bedrock client available")
            return []

    def pipes(self) -> List[dict]:
        """Returns available models."""
        print("Method called: pipes")
        return self.get_models()

    def _build_payload(self, system_prompt, messages, model_id, body: dict):
        """Helper method to build the payload for Nova API calls."""
        print("Method called: _build_payload")
        print(f"Using model ID: {model_id}")
        print(
            f"Raw messages received: {json.dumps(messages, indent=2)}"
        )  # Pretty print the messages

        # Set default system prompt if None
        if system_prompt is None:
            system_prompt = "You are an intelligent AI assistant."
            print("Using default system prompt")
        elif isinstance(system_prompt, dict):
            system_prompt = system_prompt.get(
                "content", "You are an intelligent AI assistant."
            )

        processed_messages = []
        for message in messages:
            processed_content = []
            print(f"Processing message with role: {message['role']}")

            if isinstance(message.get("content"), list):
                print("Processing list-type content")
                for item in message["content"]:
                    print(f"Content item type: {item.get('type')}")
                    if item["type"] == "text":
                        processed_content.append({"text": item["text"]})
                    elif item["type"] == "document":
                        print(f"Found document: {item.get('document_id')}")
                        # Preserve document structure in the content
                        doc_format = "txt"
                        if item["url"].endswith(".pdf"):
                            doc_format = "pdf"
                        elif item["url"].endswith(".docx"):
                            doc_format = "docx"

                        if doc_format == "docx" or doc_format == "pdf":
                            processed_content.append(
                                {
                                    "document": {
                                        "name": "MyDocument",
                                        "format": doc_format,
                                        "source": {"bytes": item.get("content", "")},
                                    }
                                }
                            )
                        else:
                            processed_content.append(
                                {
                                    "document": {
                                        "name": "MyDocument",
                                        "format": doc_format,
                                        "source": {
                                            "bytes": item.get("content", "").encode(
                                                "utf-8"
                                            )
                                        },
                                    }
                                }
                            )
                    elif item["type"] == "image" or item.get("type") == "image_url":
                        if "image_url" in item:
                            processed_content.append(
                                self.process_image(item["image_url"])
                            )
                        elif "url" in item:
                            processed_content.append(self.process_image(item))
            else:
                print("Processing string-type content")
                processed_content = [{"text": message.get("content", "")}]

            processed_messages.append(
                {"role": message["role"], "content": processed_content}
            )

        payload = {
            "modelId": model_id,
            "messages": processed_messages,
        }

        if system_prompt:
            payload["system"] = [{"text": system_prompt}]

        inference_config = {}
        if body.get("temperature") is not None:
            inference_config["temperature"] = float(body.get("temperature"))
        if body.get("top_p") is not None:
            inference_config["topP"] = float(body.get("top_p"))
        if inference_config:
            payload["inferenceConfig"] = inference_config

        additional_fields = {}
        if body.get("top_k") is not None:
            additional_fields["top_k"] = int(body.get("top_k"))
        if additional_fields:
            payload["additionalModelRequestFields"] = {
                "inferenceConfig": additional_fields
            }

        print("Final payload structure:")
        print(f"- Number of messages: {len(payload['messages'])}")
        print(f"- System prompt: {system_prompt[:100]}...")  # First 100 chars
        print(json.dumps(payload, indent=2))  # Pretty print the final payload
        return payload

    def converse_nova(self, payload):
        """Sends a complete payload to Nova and returns the response."""
        print("Method called: converse_nova")
        try:
            bedrock_runtime = self.get_bedrock_runtime_client()
            if not bedrock_runtime:
                raise Exception("Failed to initialize Bedrock runtime client")

            print("Sending request to Nova")
            response = bedrock_runtime.converse(**payload)
            print("Response received from Nova")
            return response["output"]["message"]["content"][0]["text"]

        except ClientError as err:
            print(f"Client error in converse_nova: {err}")
            raise

    def converse_nova_stream(self, payload):
        """Sends a complete payload to Nova and streams the response."""
        print("Method called: converse_nova_stream")
        try:
            bedrock_runtime = self.get_bedrock_runtime_client()
            if not bedrock_runtime:
                raise Exception("Failed to initialize Bedrock runtime client")

            print("Removing non-streaming fields from payload")
            payload.pop("additionalModelRequestFields", None)

            print("Starting streaming response from Nova")
            streaming_response = bedrock_runtime.converse_stream(**payload)
            for event in streaming_response["stream"]:
                print(f"Processing event: {event}")
                if (
                    "contentBlockDelta" in event
                    and "delta" in event["contentBlockDelta"]
                    and "text" in event["contentBlockDelta"]["delta"]
                ):
                    chunk = event["contentBlockDelta"]["delta"]["text"]
                    print(f"Yielding chunk content: {chunk}")
                    yield chunk
                else:
                    print(f"Event did not contain expected content structure")

        except ClientError as err:
            print(f"Client error in converse_nova_stream: {err}")
            raise

    def _extract_user_prompt(self, messages):
        """Helper method to extract user prompt from messages."""
        print("Method called: _extract_user_prompt")
        user_prompt = ""
        for message in messages:
            if message["role"] == "user":
                if isinstance(message.get("content"), list):
                    for item in message["content"]:
                        if item["type"] == "text":
                            user_prompt += item["text"]
                else:
                    user_prompt += message.get("content", "")
        print(f"Extracted user prompt of length: {len(user_prompt)}")
        return user_prompt

    def process_image(self, image: dict):
        """Processes image data for Nova vision capabilities."""
        print("Method called: process_image")
        img_stream = None
        image_format = "jpeg"
        if image.get("url", "").startswith("data:image"):
            print("Processing base64 image")
            if "," in image["url"]:
                base64_string = image["url"].split(",")[1]
                image_data = base64.b64decode(base64_string)
                img_stream = BytesIO(image_data)
                if "jpeg" in image["url"]:
                    image_format = "jpeg"
                elif "png" in image["url"]:
                    image_format = "png"
                elif "gif" in image["url"]:
                    image_format = "gif"
                elif "webp" in image["url"]:
                    image_format = "webp"

        else:
            print("Downloading image from URL")
            response = requests.get(image["url"], stream=True)
            response.raise_for_status()
            img_stream = BytesIO(response.content)
            if image["url"].endswith(".png"):
                image_format = "png"
            elif image["url"].endswith(".gif"):
                image_format = "gif"
            elif image["url"].endswith(".webp"):
                image_format = "webp"

        if isinstance(img_stream, bytes):
            img_stream = BytesIO(img_stream)

        print(f"Image processed as {image_format}")

        return {
            "image": {
                "format": image_format,
                "source": {
                    "bytes": base64.b64encode(img_stream.read()).decode("utf-8")
                },
            }
        }

    def pipe(self, body: dict) -> Union[str, Generator, Iterator]:
        """Main entry point for processing requests from OpenWebUI."""
        print("\n=== Starting new pipe request ===")
        print("Method called: pipe")
        print(f"Request body: {json.dumps(body, indent=2)}")

        model_id = body.get("model")
        if "." in model_id:
            model_id = model_id.split(".", 1)[1]  # Get everything after the first dot
        self.model_id = model_id

        if not model_id:
            print("Error: No model specified in request")
            return "Error: Model not specified in request body"

        print("Processing messages")
        messages = body.get("messages", [])
        print(f"Number of messages received: {len(messages)}")

        system_message, messages = pop_system_message(messages)
        print(f"System message extracted: {system_message}")

        try:
            payload = self._build_payload(system_message, messages, model_id, body)

            if body.get("stream", False):
                print("Using streaming response")
                return self.converse_nova_stream(payload)
            else:
                print("Using non-streaming response")
                return self.converse_nova(payload)
        except Exception as e:
            print(f"Error in pipe: {str(e)}")
            print(f"Error type: {type(e)}")
            import traceback

            print(f"Traceback: {traceback.format_exc()}")
            return f"Error: {str(e)}"
